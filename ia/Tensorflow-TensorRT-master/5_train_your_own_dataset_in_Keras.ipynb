{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define configuration variables and generator to read the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'dataset/mnist/training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24888/1734601920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# read image batch by batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mtrain_data_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#inpput iameg: gray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    974\u001b[0m             \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \"\"\"\n\u001b[1;32m--> 976\u001b[1;33m     return DirectoryIterator(\n\u001b[0m\u001b[0;32m    977\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m     super(DirectoryIterator, self).__init__(\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'dataset/mnist/training'"
     ]
    }
   ],
   "source": [
    "# import the needed libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# config\n",
    "img_width, img_height = 28,28 #width & height of input image\n",
    "input_depth = 1 #1: gray image\n",
    "train_data_dir = 'dataset/mnist/training' #data training path\n",
    "testing_data_dir = 'dataset/mnist/testing' #data testing path\n",
    "epochs = 2 #number of training epoch\n",
    "batch_size = 5 #training batch size\n",
    "\n",
    "# define image generator for Keras,\n",
    "# here, we map pixel intensity to 0-1\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# read image batch by batch\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode='grayscale',#inpput iameg: gray\n",
    "    target_size=(img_width,img_height),#input image size\n",
    "    batch_size=batch_size,#batch size\n",
    "    class_mode='categorical')#categorical: one-hot encoding format class label\n",
    "testing_generator = test_datagen.flow_from_directory(\n",
    "    testing_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of filters and nodes in the fully connected layer\n",
    "NUMB_FILTER_L1 = 20\n",
    "NUMB_FILTER_L2 = 20\n",
    "NUMB_FILTER_L3 = 20\n",
    "NUMB_NODE_FC_LAYER = 10\n",
    "\n",
    "#define input image order shape\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape_val = (input_depth, img_width, img_height)\n",
    "else:\n",
    "    input_shape_val = (img_width, img_height, input_depth)\n",
    "\n",
    "#define the network\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Conv2D(NUMB_FILTER_L1, (5, 5), \n",
    "                 input_shape=input_shape_val, \n",
    "                 padding='same', name='input_tensor'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv2D(NUMB_FILTER_L2, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv2D(NUMB_FILTER_L3, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# flattening the model for fully connected layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully connected layer\n",
    "model.add(Dense(NUMB_NODE_FC_LAYER, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(train_generator.num_classes, \n",
    "                activation='softmax', name='output_tensor'))\n",
    "\n",
    "# Compilile the network\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Show the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the network\n",
    "model.fit_generator(\n",
    "    train_generator,#our training generator\n",
    "    #number of iteration per epoch = number of data / batch size\n",
    "    steps_per_epoch=np.floor(train_generator.n/batch_size),\n",
    "    epochs=epochs,#number of epoch\n",
    "    validation_data=testing_generator,#our validation generator\n",
    "    #number of iteration per epoch = number of data / batch size\n",
    "    validation_steps=np.floor(testing_generator.n / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training is done!\")\n",
    "model.save('./model/modelLeNet5.h5')\n",
    "print(\"Model is successfully stored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
